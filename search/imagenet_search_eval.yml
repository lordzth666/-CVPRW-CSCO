# Prepare dataset and network configuration.
task: "imagenet"
data: "./data/ImageNetSmall"
lmdb: 0
workers: 12
# Data augmentation
augmentation: "naive"
# Include network config.
prototxt: ""
# Input resolution
image_size: 160
num_classes: 10
downsample_ratio: 1.0
# Prepare hyperparameters for training
optimizer: sgd
# Learning rate schedule
lr_schedule: cosine
# Total batch size and LR on all GPUs.
train_batch_size: 512
val_batch_size: 256
lr: 0.256
epochs: 90
start_epochs: 0
# This is used to set the batchnorm settings.
bn_momentum: 0.01
bn_epsilon: 1e-3
# Config SE options.
se_intra_activation_fn: relu
se_output_activation_fn: sigmoid
# Exponential Moving Average.
EMA: 0.99
use_num_updates: 1
# Default regularization. This is configured for layers without a user-defined L2 regularization strength.
regularizer: 'l2'
weight_decay: 1e-5
# Configure other regularization
drop_connect: 0.0
label_smoothing: 0.0
# Report frequency
report_freq: 100
# Distributed options. Use 0, 1 as boolean variable.
multiprocessing_distributed: 0
# CUDNN deterministic:
cudnn_deterministic: 0
# AMP (Auto mixed precision)
amp: 1
# regularize_depthwise
regularize_depthwise: 1